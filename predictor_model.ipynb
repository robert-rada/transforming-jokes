{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Copy of ColBERT model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f06b9a2b5bb14009adaaa52b3ccdc420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_256cbbf3e3804e73b6fb9367279dd605",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71517f6f9a1843dca05141b043708832",
              "IPY_MODEL_6047e136750c47f486fbd45ea949ab5b"
            ]
          }
        },
        "256cbbf3e3804e73b6fb9367279dd605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71517f6f9a1843dca05141b043708832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bb54de17fb8c4978a610664a40cc440d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98dca75ec5ee40a39071ad9cb928b08e"
          }
        },
        "6047e136750c47f486fbd45ea949ab5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_953c8aaa67f549fba8608fac711c105b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 101740/? [02:06&lt;00:00, 806.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22059eb66b8d4c66b571a4fa74181321"
          }
        },
        "bb54de17fb8c4978a610664a40cc440d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98dca75ec5ee40a39071ad9cb928b08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "953c8aaa67f549fba8608fac711c105b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22059eb66b8d4c66b571a4fa74181321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b13e7db76a9847509f188abdc833f1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ce7900b1fd149fd9e9b9e1b2982a04a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ef74ca176274d07a442c16196835659",
              "IPY_MODEL_38ddc34b3fa64c2b9ca61949a509b837"
            ]
          }
        },
        "5ce7900b1fd149fd9e9b9e1b2982a04a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ef74ca176274d07a442c16196835659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2113233a523147e78c8b3f0ad23bc138",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_914d9396ad194940a18e5cbe99aa2a4a"
          }
        },
        "38ddc34b3fa64c2b9ca61949a509b837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7cfd5163da24a47aaa91b494fd6de85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12717/? [00:17&lt;00:00, 720.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f44ed5f8b0564cfbaf8e9313db18dde9"
          }
        },
        "2113233a523147e78c8b3f0ad23bc138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "914d9396ad194940a18e5cbe99aa2a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7cfd5163da24a47aaa91b494fd6de85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f44ed5f8b0564cfbaf8e9313db18dde9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEfpiXnHtTvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "bb185a1c-f42b-4c16-aabe-f556d3eb14a3"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "# !pip install -q kaggle\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kxrOCitrtGwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import subprocess\n",
        "from ast import literal_eval\n",
        "\n",
        "def run(command):\n",
        "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
        "    out, err = process.communicate()\n",
        "    print(out.decode('utf-8').strip())\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "tyx_MrIMtGw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f68dbf9b-2a58-4474-c6ea-8c67fbcea639"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "# import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "# import bert_tokenization as tokenization\n",
        "import tensorflow.keras.backend as K\n",
        "import os\n",
        "from scipy.stats import spearmanr\n",
        "from math import floor, ceil\n",
        "from transformers import *\n",
        "\n",
        "import seaborn as sns\n",
        "import string\n",
        "import re    #for regex\n",
        "\n",
        "print(tf.test.gpu_device_name())\n",
        "np.set_printoptions(suppress=True)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4K9aeP3tGw8",
        "colab_type": "text"
      },
      "source": [
        "# Choose model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2T52BTcVtGw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "\n",
        "MODEL_TYPE = 'bert-base-uncased'\n",
        "MAX_SIZE = 200\n",
        "BATCH_SIZE = 200\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKrFWq6LtGxC",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Read data and tokenizer\n",
        "\n",
        "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ax3Vv7gWtGxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HAS_ANS = False\n",
        "training_sample_count = 1000 # 4000\n",
        "training_epochs = 1 # 3\n",
        "test_count = 1000\n",
        "running_folds = 1 # 2\n",
        "MAX_SEQUENCE_LENGTH = 300"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIO_MCF-tGxS",
        "colab_type": "text"
      },
      "source": [
        "### original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ban90ZpltGxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "54e18466-e003-45ce-9a2a-9c96b7cf5c9c"
      },
      "source": [
        "import io\n",
        "\n",
        "\n",
        "df = pd.read_csv('dadjokes.csv', sep='<endoftext>')\n",
        "# df = df.dropna()\n",
        "# df['humor'] = df['humor'].astype('bool')\n",
        "\n",
        "\n",
        "df_train = pd.read_csv('dadjokes_train.csv', sep='<endoftext>')\n",
        "display(df_train.head(3))\n",
        "# df_train = df_train[:training_sample_count*5]\n",
        "# df_train = df_train.dropna()\n",
        "# df_train['humor'] = df_train['humor'].astype('bool')\n",
        "\n",
        "df_test = pd.read_csv('dadjokes_test.csv', sep='<endoftext>')\n",
        "display(df_test.head(3))\n",
        "# df_test = df_test[:test_count]\n",
        "# df_test = df_test.dropna()\n",
        "# df_test['humor'] = df_test['humor'].astype('bool')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I spoke to a German about walls Apparently his...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What makes a dad joke a dad joke? Isn't it app...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a rich mushroom? A fungi to b...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  I spoke to a German about walls Apparently his...  False\n",
              "1  What makes a dad joke a dad joke? Isn't it app...  False\n",
              "2  What do you call a rich mushroom? A fungi to b...  False"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TIFU by letting my dog give birth to a litter ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did 50 cent say when his grandmother was ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After being on an episode of Say Yes To The Dr...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  TIFU by letting my dog give birth to a litter ...  False\n",
              "1  What did 50 cent say when his grandmother was ...  False\n",
              "2  After being on an episode of Say Yes To The Dr...  False"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-KOdSsd7tGxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "c5cf4229-8940-46e7-b77d-02100e6bc88b"
      },
      "source": [
        "test_df_y = df_test.copy()\n",
        "del df_test['humor']\n",
        "\n",
        "df_sub = test_df_y.copy()\n",
        "\n",
        "print(len(df),len(df_train),len(df_test))\n",
        "display(df_train.head())\n",
        "display(df_test.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127174 101740 12717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I spoke to a German about walls Apparently his...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What makes a dad joke a dad joke? Isn't it app...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a rich mushroom? A fungi to b...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Don't make fun of Terry &amp;#x200B;  If he kills ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Did you hear about the kidnapping at school? I...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  I spoke to a German about walls Apparently his...  False\n",
              "1  What makes a dad joke a dad joke? Isn't it app...  False\n",
              "2  What do you call a rich mushroom? A fungi to b...  False\n",
              "3  Don't make fun of Terry &#x200B;  If he kills ...  False\n",
              "4  Did you hear about the kidnapping at school? I...  False"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TIFU by letting my dog give birth to a litter ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did 50 cent say when his grandmother was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After being on an episode of Say Yes To The Dr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A steak pun Is rare and medium well done</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Did you hear about the blind lady that fell in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  TIFU by letting my dog give birth to a litter ...\n",
              "1  What did 50 cent say when his grandmother was ...\n",
              "2  After being on an episode of Say Yes To The Dr...\n",
              "3           A steak pun Is rare and medium well done\n",
              "4  Did you hear about the blind lady that fell in..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aBPzSXXKtGxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c95c7f97-7884-4955-ecbc-4eaed879299a"
      },
      "source": [
        "print(list(df_train.columns))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['text', 'humor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vj17XQn9tGxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "fba6dfa5-01ff-487d-f46d-97c2ea48e034"
      },
      "source": [
        "output_categories = list(df_train.columns[[1]])\n",
        "input_categories = list(df_train.columns[[0]])\n",
        "\n",
        "if HAS_ANS:\n",
        "    output_categories = list(df_train.columns[11:])\n",
        "    input_categories = list(df_train.columns[[1,2,5]])\n",
        "    \n",
        "\n",
        "TARGET_COUNT = len(output_categories)\n",
        "\n",
        "print('\\ninput categories:\\n\\t', input_categories)\n",
        "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
        "print('\\noutput categories:\\n\\t', output_categories)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "input categories:\n",
            "\t ['text']\n",
            "\n",
            "output TARGET_COUNT:\n",
            "\t 1\n",
            "\n",
            "output categories:\n",
            "\t ['humor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTeBOTyftGxh",
        "colab_type": "raw"
      },
      "source": [
        "#### 2. Preprocessing functions\n",
        "\n",
        "These are some functions that will be used to preprocess the raw text data into useable Bert inputs.<br>\n",
        "\n",
        "*update 4:* credits to [Minh](https://www.kaggle.com/dathudeptrai) for this implementation. If I'm not mistaken, it could be used directly with other Huggingface transformers too! Note that due to the 2 x 512 input, it will require significantly more memory when finetuning BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eO7ZZJwutGxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
        "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
        "    \n",
        "    def return_id(str1, str2, truncation_strategy, length):\n",
        "\n",
        "        inputs = tokenizer.encode_plus(str1, str2,\n",
        "            add_special_tokens=True,\n",
        "            max_length=length,\n",
        "            truncation_strategy=truncation_strategy)\n",
        "        \n",
        "        input_ids =  inputs[\"input_ids\"]\n",
        "        input_masks = [1] * len(input_ids)\n",
        "        input_segments = inputs[\"token_type_ids\"]\n",
        "        padding_length = length - len(input_ids)\n",
        "        padding_id = tokenizer.pad_token_id\n",
        "        input_ids = input_ids + ([padding_id] * padding_length)\n",
        "        input_masks = input_masks + ([0] * padding_length)\n",
        "        input_segments = input_segments + ([0] * padding_length)\n",
        "        \n",
        "        return [input_ids, input_masks, input_segments]\n",
        "    \n",
        "    input_ids_q, input_masks_q, input_segments_q = return_id(\n",
        "        title, None, 'longest_first', max_sequence_length)\n",
        "    \n",
        "    input_ids_a, input_masks_a, input_segments_a = return_id(\n",
        "        '', None, 'longest_first', max_sequence_length)\n",
        "        \n",
        "    return [input_ids_q, input_masks_q, input_segments_q,\n",
        "            input_ids_a, input_masks_a, input_segments_a]\n",
        "\n",
        "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
        "    input_ids_q, input_masks_q, input_segments_q = [], [], []\n",
        "    input_ids_a, input_masks_a, input_segments_a = [], [], []\n",
        "    for _, instance in tqdm(df[columns].iterrows()):\n",
        "        t, q, a = instance.text, instance.text, instance.text\n",
        "\n",
        "        try:\n",
        "          ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n",
        "        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          print(t)\n",
        "        \n",
        "        input_ids_q.append(ids_q)\n",
        "        input_masks_q.append(masks_q)\n",
        "        input_segments_q.append(segments_q)\n",
        "        input_ids_a.append(ids_a)\n",
        "        input_masks_a.append(masks_a)\n",
        "        input_segments_a.append(segments_a)\n",
        "        \n",
        "    return [np.asarray(input_ids_q, dtype=np.int32), \n",
        "            np.asarray(input_masks_q, dtype=np.int32), \n",
        "            np.asarray(input_segments_q, dtype=np.int32),\n",
        "            np.asarray(input_ids_a, dtype=np.int32), \n",
        "            np.asarray(input_masks_a, dtype=np.int32), \n",
        "            np.asarray(input_segments_a, dtype=np.int32)]\n",
        "\n",
        "def compute_output_arrays(df, columns):\n",
        "    return np.asarray(df[columns])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_qX3MUHwtGxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "f06b9a2b5bb14009adaaa52b3ccdc420",
            "256cbbf3e3804e73b6fb9367279dd605",
            "71517f6f9a1843dca05141b043708832",
            "6047e136750c47f486fbd45ea949ab5b",
            "bb54de17fb8c4978a610664a40cc440d",
            "98dca75ec5ee40a39071ad9cb928b08e",
            "953c8aaa67f549fba8608fac711c105b",
            "22059eb66b8d4c66b571a4fa74181321",
            "b13e7db76a9847509f188abdc833f1ca",
            "5ce7900b1fd149fd9e9b9e1b2982a04a",
            "8ef74ca176274d07a442c16196835659",
            "38ddc34b3fa64c2b9ca61949a509b837",
            "2113233a523147e78c8b3f0ad23bc138",
            "914d9396ad194940a18e5cbe99aa2a4a",
            "e7cfd5163da24a47aaa91b494fd6de85",
            "f44ed5f8b0564cfbaf8e9313db18dde9"
          ]
        },
        "outputId": "48a6ba65-e3e4-445f-d0ac-ed059c3138ff"
      },
      "source": [
        "outputs = compute_output_arrays(df_train, output_categories)\n",
        "inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f06b9a2b5bb14009adaaa52b3ccdc420",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b13e7db76a9847509f188abdc833f1ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjYY6lbPnHeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "b5b1f5aa-e2fd-40fc-e916-abe420db2b8c"
      },
      "source": [
        "print(outputs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGJJ33z7tGxr",
        "colab_type": "text"
      },
      "source": [
        "## 3. Create model\n",
        "\n",
        "~~`compute_spearmanr()`~~ `mean_squared_error` is used to compute the competition metric for the validation set\n",
        "<br><br>\n",
        "`create_model()` contains the actual architecture that will be used to finetune BERT to our dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XpFKbaKutGxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    config = BertConfig() # print(config) to see settings\n",
        "    config.output_hidden_states = False # Set to True to obtain hidden states\n",
        "    # caution: when using e.g. XLNet, XLNetConfig() will automatically use xlnet-large config\n",
        "    \n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "    \n",
        "    # if config.output_hidden_states = True, obtain hidden states via bert_model(...)[-1]\n",
        "    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\n",
        "    a_embedding = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)[0]\n",
        "    \n",
        "    q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\n",
        "    a = tf.keras.layers.GlobalAveragePooling1D()(a_embedding)\n",
        "    \n",
        "#     x = tf.keras.layers.Concatenate()([q, q])\n",
        "    \n",
        "    x = tf.keras.layers.Dropout(0.2)(q)\n",
        "    \n",
        "    x = tf.keras.layers.Dense(TARGET_COUNT, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, ], outputs=x)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_XapikwtGxv",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Obtain inputs and targets, as well as the indices of the train/validation splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iH1Ew37ntGxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0eca5d80-441c-4184-82f1-77f142e633e2"
      },
      "source": [
        "output_categories"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['humor']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzMt28vtGx1",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training, validation and testing\n",
        "\n",
        "Loops over the folds in gkf and trains each fold for 3 epochs --- with a learning rate of 3e-5 and batch_size of 6. A simple binary crossentropy is used as the objective-/loss-function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gXq-A_sYtGx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "797a0bf3-1d3b-4685-9356-c8afdf3697b7"
      },
      "source": [
        "# Evaluation Metrics\n",
        "import sklearn\n",
        "def print_evaluation_metrics(y_true, y_pred, label='', is_regression=True, label2=''):\n",
        "    print('==================', label2)\n",
        "    ### For regression\n",
        "    if is_regression:\n",
        "        print('mean_absolute_error',label,':', sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
        "        print('mean_squared_error',label,':', sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
        "        print('r2 score',label,':', sklearn.metrics.r2_score(y_true, y_pred))\n",
        "        #     print('max_error',label,':', sklearn.metrics.max_error(y_true, y_pred))\n",
        "        return sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
        "    else:\n",
        "        ### FOR Classification\n",
        "        print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
        "        print('average_precision_score',label,':', sklearn.metrics.average_precision_score(y_true, y_pred))\n",
        "        print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
        "        print('accuracy_score',label,':', sklearn.metrics.accuracy_score(y_true, y_pred))\n",
        "        print('f1_score',label,':', sklearn.metrics.f1_score(y_true, y_pred))\n",
        "        \n",
        "        matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
        "        print(matrix)\n",
        "        TP,TN,FP,FN = matrix[1][1],matrix[0][0],matrix[0][1],matrix[1][0]\n",
        "        Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
        "        Precision = TP/(TP+FP)\n",
        "        Recall = TP/(TP+FN)\n",
        "        F1 = 2*(Recall * Precision) / (Recall + Precision)\n",
        "        print('Acc', Accuracy, 'Prec', Precision, 'Rec', Recall, 'F1',F1)\n",
        "        return sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "print_evaluation_metrics([1,0], [0.9,0.1], '', True)\n",
        "print_evaluation_metrics([1,0], [1,1], '', False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================== \n",
            "mean_absolute_error  : 0.09999999999999999\n",
            "mean_squared_error  : 0.009999999999999998\n",
            "r2 score  : 0.96\n",
            "================== \n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.5\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.5\n",
            "f1_score  : 0.6666666666666666\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "Acc 0.5 Prec 0.5 Rec 1.0 F1 0.6666666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K3zvBbptGx4",
        "colab_type": "text"
      },
      "source": [
        "### Loss function selection\n",
        "Regression problem between 0 and 1, so binary_crossentropy and mean_absolute_error seem good.\n",
        "\n",
        "Here are the explanations: https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "92vt49fytGx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "f4cb0f89-cc03-4866-817d-6170040e324b"
      },
      "source": [
        "min_acc = 1000000\n",
        "min_test = []\n",
        "valid_preds = []\n",
        "test_preds = []\n",
        "best_model = False\n",
        "# for LR in np.arange(1e-5, 2e-5, 3e-5).tolist():\n",
        "for LR in [1e-5]:\n",
        "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
        "    print('LR=', LR)\n",
        "    gkf = GroupKFold(n_splits=5).split(X=df_train.text, groups=df_train.text)\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "        if fold not in range(running_folds):\n",
        "            continue\n",
        "        train_inputs = [(inputs[i][train_idx])[:training_sample_count] for i in range(len(inputs))]\n",
        "        train_outputs = (outputs[train_idx])[:training_sample_count]\n",
        "\n",
        "        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
        "        valid_outputs = outputs[valid_idx]\n",
        "        # valid_inputs = valid_inputs[:2]\n",
        "        # valid_outputs = valid_outputs[:2]\n",
        "\n",
        "        print(np.array(train_inputs).shape, np.array(train_outputs).shape)\n",
        "#         print(train_idx[:10], valid_idx[:10])\n",
        "\n",
        "        K.clear_session()\n",
        "        model = create_model()\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "        for xx in range(1):\n",
        "            model.fit(train_inputs, train_outputs, epochs=training_epochs, batch_size=6)\n",
        "            print('finished fit')\n",
        "            # model.save_weights(f'bert-{fold}.h5')\n",
        "            valid_preds.append(model.predict(valid_inputs, verbose=1))\n",
        "            print('finished predict')\n",
        "            #rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n",
        "            #print('validation score = ', rho_val)\n",
        "            acc = print_evaluation_metrics(np.array(valid_outputs), np.array(valid_preds[-1]), 'on #'+str(xx+1))\n",
        "            print('acc', acc)\n",
        "            if acc < min_acc:\n",
        "                print('new acc >> ', acc)\n",
        "                min_acc = acc\n",
        "                best_model = model\n",
        "#                 min_test = model.predict(test_inputs)\n",
        "#                 test_preds.append(min_test)\n",
        "            print(' ')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "LR= 1e-05\n",
            "(6, 1000, 300) (1000, 1)\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "167/167 [==============================] - 135s 809ms/step - loss: 0.3596\n",
            "finished fit\n",
            "636/636 [==============================] - 774s 1s/step\n",
            "finished predict\n",
            "================== \n",
            "mean_absolute_error on #1 : 0.2274091\n",
            "mean_squared_error on #1 : 0.11687557\n",
            "r2 score on #1 : 0.003427175150767958\n",
            "acc 0.11687557\n",
            "new acc >>  0.11687557\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-raNGO3ntGx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06f3451b-d0a7-4925-9533-72ff6179759b"
      },
      "source": [
        "print('best acc >> ', acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best acc >>  0.11687557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mJlyNotStGx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(valid_inputs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cGxIcTLDtGyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "00ebbacb-bdb4-41f2-b9c0-eefb8ae00738"
      },
      "source": [
        "print(valid_outputs.shape, valid_preds[-1].shape)\n",
        "print_evaluation_metrics(np.array(valid_outputs), np.array(valid_preds[-1]), '')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20348, 1) (20348, 1)\n",
            "================== \n",
            "mean_absolute_error  : 0.2274091\n",
            "mean_squared_error  : 0.11687557\n",
            "r2 score  : 0.003427175150767958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11687557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iHAojuRqtGyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f51178ba-40c3-49dc-876a-bb40bf05ab59"
      },
      "source": [
        "# %%time\n",
        "min_test = best_model.predict(test_inputs, verbose=1)\n",
        "\n",
        "## use min_test\n",
        "# min_test"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "398/398 [==============================] - 481s 1s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uW7IksGGtGyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.to_csv('df_test.csv')\n",
        "test_df_y.to_csv('test_df_y.csv')\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1WgMRQutGyS",
        "colab_type": "text"
      },
      "source": [
        "## Regression submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NOO4R1B4tGyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "5474a881-b327-4811-d901-10f71f03f80f"
      },
      "source": [
        "df_sub = test_df_y.copy()\n",
        "# df_sub['pred'] = np.average(test_preds, axis=0) # for weighted average set weights=[...]\n",
        "df_sub['pred'] = min_test\n",
        "\n",
        "\n",
        "print_evaluation_metrics(df_sub['humor'], df_sub['pred'], '', True)\n",
        "\n",
        "\n",
        "df_sub.to_csv('sub1.csv', index=False)\n",
        "df_sub.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================== \n",
            "mean_absolute_error  : 0.22628358\n",
            "mean_squared_error  : 0.11555437\n",
            "r2 score  : 0.0022002082186755034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TIFU by letting my dog give birth to a litter ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.105298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did 50 cent say when his grandmother was ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.113288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After being on an episode of Say Yes To The Dr...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.138661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A steak pun Is rare and medium well done</td>\n",
              "      <td>False</td>\n",
              "      <td>0.112460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Did you hear about the blind lady that fell in...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.150808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor      pred\n",
              "0  TIFU by letting my dog give birth to a litter ...  False  0.105298\n",
              "1  What did 50 cent say when his grandmother was ...  False  0.113288\n",
              "2  After being on an episode of Say Yes To The Dr...  False  0.138661\n",
              "3           A steak pun Is rare and medium well done  False  0.112460\n",
              "4  Did you hear about the blind lady that fell in...  False  0.150808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQTBcDhMtGyW",
        "colab_type": "text"
      },
      "source": [
        "## Binary submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UaiUnDbotGyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b95094dc-f90e-4712-ef70-0ad9af383bf2"
      },
      "source": [
        "for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
        "    df_sub['pred_bi'] = (df_sub['pred'] > split)\n",
        "\n",
        "    print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
        "\n",
        "    df_sub.to_csv('sub3.csv', index=False)\n",
        "    df_sub.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================== SPLIT on 0.1\n",
            "balanced_accuracy_score  : 0.5231034657668097\n",
            "average_precision_score  : 0.13929119093715203\n",
            "balanced_accuracy_score  : 0.5231034657668097\n",
            "accuracy_score  : 0.27498623889282064\n",
            "f1_score  : 0.24115226337448561\n",
            "[[2032 8985]\n",
            " [ 235 1465]]\n",
            "Acc 0.27498623889282064 Prec 0.14019138755980862 Rec 0.861764705882353 F1 0.24115226337448561\n",
            "================== SPLIT on 0.2\n",
            "balanced_accuracy_score  : 0.5084470257196099\n",
            "average_precision_score  : 0.1366913045288271\n",
            "balanced_accuracy_score  : 0.5084470257196099\n",
            "accuracy_score  : 0.8503577887866636\n",
            "f1_score  : 0.06943765281173593\n",
            "[[10743   274]\n",
            " [ 1629    71]]\n",
            "Acc 0.8503577887866636 Prec 0.20579710144927535 Rec 0.04176470588235294 F1 0.06943765281173593\n",
            "================== SPLIT on 0.30000000000000004\n",
            "balanced_accuracy_score  : 0.4997730779704094\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.4997730779704094\n",
            "accuracy_score  : 0.8659274986238893\n",
            "f1_score  : 0.0\n",
            "[[11012     5]\n",
            " [ 1700     0]]\n",
            "Acc 0.8659274986238893 Prec 0.0 Rec 0.0 F1 nan\n",
            "================== SPLIT on 0.4\n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.8663206731147283\n",
            "f1_score  : 0.0\n",
            "[[11017     0]\n",
            " [ 1700     0]]\n",
            "Acc 0.8663206731147283 Prec nan Rec 0.0 F1 nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================== SPLIT on 0.5\n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.8663206731147283\n",
            "f1_score  : 0.0\n",
            "[[11017     0]\n",
            " [ 1700     0]]\n",
            "Acc 0.8663206731147283 Prec nan Rec 0.0 F1 nan\n",
            "================== SPLIT on 0.6\n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.8663206731147283\n",
            "f1_score  : 0.0\n",
            "[[11017     0]\n",
            " [ 1700     0]]\n",
            "Acc 0.8663206731147283 Prec nan Rec 0.0 F1 nan\n",
            "================== SPLIT on 0.7000000000000001\n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.8663206731147283\n",
            "f1_score  : 0.0\n",
            "[[11017     0]\n",
            " [ 1700     0]]\n",
            "Acc 0.8663206731147283 Prec nan Rec 0.0 F1 nan\n",
            "================== SPLIT on 0.8\n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.8663206731147283\n",
            "f1_score  : 0.0\n",
            "[[11017     0]\n",
            " [ 1700     0]]\n",
            "Acc 0.8663206731147283 Prec nan Rec 0.0 F1 nan\n",
            "================== SPLIT on 0.9\n",
            "balanced_accuracy_score  : 0.5\n",
            "average_precision_score  : 0.13367932688527168\n",
            "balanced_accuracy_score  : 0.5\n",
            "accuracy_score  : 0.8663206731147283\n",
            "f1_score  : 0.0\n",
            "[[11017     0]\n",
            " [ 1700     0]]\n",
            "Acc 0.8663206731147283 Prec nan Rec 0.0 F1 nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThYs_oAwfYNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "a30ea760-c5a4-4b69-81aa-59f146ab7bc7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "best_model.save('/content/gdrive/My Drive/dadjokes_model')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: dadjokes_model/assets\n",
            "  adding: content/dadjokes_model/ (stored 0%)\n",
            "  adding: content/dadjokes_model/variables/ (stored 0%)\n",
            "  adding: content/dadjokes_model/variables/variables.index (deflated 81%)\n",
            "  adding: content/dadjokes_model/variables/variables.data-00000-of-00002 (deflated 36%)\n",
            "  adding: content/dadjokes_model/variables/variables.data-00001-of-00002 (deflated 19%)\n",
            "  adding: content/dadjokes_model/assets/ (stored 0%)\n",
            "  adding: content/dadjokes_model/saved_model.pb (deflated 92%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_06966a56-7819-4852-b7ff-34e8a0f39b9e\", \"dadjokes.zip\", 1055505791)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}